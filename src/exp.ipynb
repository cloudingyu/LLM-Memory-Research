{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc52e257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在加载主模型 (Qwen2.5-1.5B)...\n",
      "正在加载向量模型 (all-MiniLM-L6-v2)...\n",
      ">>> 环境加载完成。\n"
     ]
    }
   ],
   "source": [
    "# %% [Cell 1] 环境安装与模型加载\n",
    "# ==============================================================================\n",
    "# 目的: 安装依赖，加载 Qwen2.5-1.5B 和 Embedding 模型。\n",
    "# ==============================================================================\n",
    "\n",
    "# !pip install transformers accelerate bitsandbytes sentence-transformers wandb termcolor tqdm -q\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import difflib\n",
    "import wandb\n",
    "from statistics import mean\n",
    "from collections import deque\n",
    "from termcolor import colored\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "print(colored(\"正在加载主模型 (Qwen2.5-1.5B)...\", \"cyan\"))\n",
    "MODEL_ID = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_ID, torch_dtype=\"auto\", device_map=\"auto\")\n",
    "\n",
    "print(colored(\"正在加载向量模型 (all-MiniLM-L6-v2)...\", \"cyan\"))\n",
    "embedder = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def generate(prompt, max_tokens=200):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(**inputs, max_new_tokens=max_tokens, temperature=0.01)\n",
    "    response = tokenizer.batch_decode(outputs[:, inputs.input_ids.shape[1]:], skip_special_tokens=True)[0]\n",
    "    return response.strip()\n",
    "\n",
    "print(colored(\">>> 环境加载完成。\", \"green\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0ae948a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 记忆机制定义完毕。\n"
     ]
    }
   ],
   "source": [
    "# %% [Cell 2] 定义五种记忆机制 (含真实 LLM 调用)\n",
    "# ==============================================================================\n",
    "# 目的: 定义 Baseline, RAG, Cheatsheet, Titans, TAC。\n",
    "# 修改: 全员增加 add_special 接口，确保公平性。\n",
    "# ==============================================================================\n",
    "\n",
    "class BaseMemory:\n",
    "    def add(self, query, response): pass\n",
    "    def add_special(self, query, thought, response): \n",
    "        # 默认回退到普通 add，子类可覆盖\n",
    "        self.add(query, response)\n",
    "    def get_context(self, query): return \"\"\n",
    "    def reset(self): pass\n",
    "\n",
    "# 1. Baseline\n",
    "class ConcatMemory(BaseMemory):\n",
    "    def __init__(self, limit=3):\n",
    "        self.limit = limit\n",
    "        self.history = deque(maxlen=limit)\n",
    "    def add(self, query, response):\n",
    "        self.history.append(f\"User: {query}\\nAI: {response}\")\n",
    "    def add_special(self, query, thought, response):\n",
    "        # Baseline 忽略 thought，行为与 add 相同\n",
    "        self.add(query, response)\n",
    "    def get_context(self, query):\n",
    "        return \"\\n\".join(self.history)\n",
    "    def reset(self): self.history.clear()\n",
    "\n",
    "# 2. RAG\n",
    "class RAGMemory(BaseMemory):\n",
    "    def __init__(self, top_k=2):\n",
    "        self.top_k = top_k\n",
    "        self.corpus = [] \n",
    "        self.embeddings = None\n",
    "    def add(self, query, response):\n",
    "        text = f\"User: {query}\\nAI: {response}\"\n",
    "        self._embed_and_store(text)\n",
    "    def add_special(self, query, thought, response):\n",
    "        # RAG 将 thought 也加入索引，增加语义丰富度\n",
    "        text = f\"User: {query}\\nThought: {thought}\\nAI: {response}\"\n",
    "        self._embed_and_store(text)\n",
    "    def _embed_and_store(self, text):\n",
    "        vec = embedder.encode([text])\n",
    "        self.corpus.append(text)\n",
    "        if self.embeddings is None: self.embeddings = vec\n",
    "        else: self.embeddings = np.vstack([self.embeddings, vec])\n",
    "    def get_context(self, query):\n",
    "        if self.embeddings is None: return \"\"\n",
    "        query_vec = embedder.encode([query])\n",
    "        scores = cosine_similarity(query_vec, self.embeddings)[0]\n",
    "        top_indices = np.argsort(scores)[-self.top_k:]\n",
    "        top_indices = sorted(top_indices)\n",
    "        return \"[RAG Context]:\\n\" + \"\\n\".join([self.corpus[i] for i in top_indices])\n",
    "    def reset(self):\n",
    "        self.corpus = []\n",
    "        self.embeddings = None\n",
    "\n",
    "# 3. Cheatsheet (High Latency)\n",
    "class DynamicCheatsheetMemory(BaseMemory):\n",
    "    def __init__(self):\n",
    "        self.cheatsheet = \"No facts yet.\"\n",
    "    def add(self, query, response):\n",
    "        self._update_knowledge(query, \"\", response)\n",
    "    def add_special(self, query, thought, response):\n",
    "        # 给 Curator 提供 Thought 上下文\n",
    "        self._update_knowledge(query, thought, response)\n",
    "    def _update_knowledge(self, query, thought, response):\n",
    "        thought_part = f\"\\nThought: {thought}\" if thought else \"\"\n",
    "        prompt = (f\"Current Knowledge:\\n{self.cheatsheet}\\nNew Interaction:\\nUser: {query}{thought_part}\\nAI: {response}\\n\"\n",
    "                  \"Task: Update Knowledge with new facts. Keep it concise.\\nUpdated Knowledge:\")\n",
    "        self.cheatsheet = generate(prompt, max_tokens=100)\n",
    "    def get_context(self, query):\n",
    "        return f\"[Cheatsheet]:\\n{self.cheatsheet}\"\n",
    "    def reset(self): self.cheatsheet = \"No facts yet.\"\n",
    "\n",
    "# 4. Titans (High Latency)\n",
    "class TitansMemory(BaseMemory):\n",
    "    def __init__(self):\n",
    "        self.state = \"Empty state.\"\n",
    "    def add(self, query, response):\n",
    "        self._compress_state(query, \"\", response)\n",
    "    def add_special(self, query, thought, response):\n",
    "        # 给 Neural Memory 提供 Thought 上下文\n",
    "        self._compress_state(query, thought, response)\n",
    "    def _compress_state(self, query, thought, response):\n",
    "        thought_part = f\"\\nThought: {thought}\" if thought else \"\"\n",
    "        prompt = (f\"Memory State:\\n{self.state}\\nInput:\\nUser: {query}{thought_part}\\nAI: {response}\\n\"\n",
    "                  \"Task: Compress Input into Memory State. Retain critical info.\\nNew State:\")\n",
    "        self.state = generate(prompt, max_tokens=100)\n",
    "    def get_context(self, query):\n",
    "        return f\"[Titans State]:\\n{self.state}\"\n",
    "    def reset(self): self.state = \"Empty state.\"\n",
    "\n",
    "# 5. TAC (Ours - Low Latency)\n",
    "class TACMemory(BaseMemory):\n",
    "    def __init__(self, limit=3):\n",
    "        self.limit = limit\n",
    "        self.anchor = \"N/A\"\n",
    "        self.window = deque(maxlen=limit)\n",
    "    def add_special(self, query, thought, response):\n",
    "        if len(thought) > 10: self.anchor = thought\n",
    "        self.window.append(f\"User: {query}\\nAI: {response}\")\n",
    "    def add(self, query, response):\n",
    "        self.window.append(f\"User: {query}\\nAI: {response}\")\n",
    "    def get_context(self, query):\n",
    "        hist = \"\\n\".join(self.window)\n",
    "        return f\"[Anchor Thought]: {self.anchor}\\n[Window]:\\n{hist}\"\n",
    "    def reset(self):\n",
    "        self.anchor = \"N/A\"\n",
    "        self.window.clear()\n",
    "\n",
    "print(colored(\">>> 记忆机制定义完毕。\", \"green\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f822ee0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 任务逻辑优化完毕 (公平接口 + 固定测试集)。\n"
     ]
    }
   ],
   "source": [
    "# %% [Cell 3] 真实干扰数据集与任务逻辑\n",
    "# ==============================================================================\n",
    "# 目的: 准备真实问答数据，定义带评分的任务函数。\n",
    "# 修改: 移除 isinstance 判断，统一使用 add_special 接口。\n",
    "# ==============================================================================\n",
    "\n",
    "REAL_DISTRACTORS = [\n",
    "    (\"What is the capital of Australia?\", \"Canberra.\"),\n",
    "    (\"Who wrote '1984'?\", \"George Orwell.\"),\n",
    "    (\"Define photosynthesis.\", \"Plants use sunlight to make food.\"),\n",
    "    (\"Speed of light?\", \"299,792,458 m/s.\"),\n",
    "    (\"Pythagorean theorem?\", \"a^2 + b^2 = c^2.\"),\n",
    "    (\"Boiling point of water?\", \"100 C.\"),\n",
    "    (\"Who painted Mona Lisa?\", \"Da Vinci.\"),\n",
    "    (\"What is a black hole?\", \"Strong gravity region.\"),\n",
    "    (\"What is GPU?\", \"Graphics Processing Unit.\"),\n",
    "    (\"Who is Elon Musk?\", \"Tesla CEO.\"),\n",
    "    (\"What is Python?\", \"Programming language.\"),\n",
    "    (\"Quantum entanglement?\", \"Connected particles.\"),\n",
    "    (\"Tallest mountain?\", \"Everest.\"),\n",
    "    (\"Discovered penicillin?\", \"Fleming.\"),\n",
    "    (\"Currency of Japan?\", \"Yen.\"),\n",
    "    (\"HTTP stands for?\", \"Hypertext Transfer Protocol.\"),\n",
    "    (\"First on moon?\", \"Armstrong.\"),\n",
    "    (\"What is DNA?\", \"Genetic instructions.\"),\n",
    "    (\"Largest ocean?\", \"Pacific.\"),\n",
    "    (\"Romeo and Juliet author?\", \"Shakespeare.\")\n",
    "]\n",
    "\n",
    "def get_distractors(count):\n",
    "    pool = REAL_DISTRACTORS * (count // len(REAL_DISTRACTORS) + 1)\n",
    "    return random.sample(pool, count)\n",
    "\n",
    "def calculate_soft_score(ground_truth, prediction):\n",
    "    t = ground_truth.lower().strip()\n",
    "    p = prediction.lower().strip()\n",
    "    if t in p: return 1.0\n",
    "    similarity = difflib.SequenceMatcher(None, t, p).ratio()\n",
    "    return 0.0 if similarity < 0.25 else similarity\n",
    "\n",
    "# Task A: NIAH - 公平版 (接收固定的 code 和 distractors)\n",
    "def task_niah(mem, fixed_code, fixed_distractors):\n",
    "    mem.reset()\n",
    "    q_n, a_n = \"Set protocol code.\", f\"Code is {fixed_code}.\"\n",
    "    \n",
    "    # 统一生成 Thought，所有方法都有权看到\n",
    "    thought = f\"The activation code is {fixed_code}. I must keep this in mind.\"\n",
    "    \n",
    "    # 统一调用 add_special\n",
    "    mem.add_special(q_n, thought, a_n)\n",
    "    \n",
    "    # 注入干扰项 (无 Thought)\n",
    "    for q, a in fixed_distractors:\n",
    "        mem.add(q, a)\n",
    "        \n",
    "    resp = generate(f\"Context:\\n{mem.get_context('Code?')}\\n\\nUser: Code?\\nAnswer:\")\n",
    "    return calculate_soft_score(fixed_code, resp)\n",
    "\n",
    "# Task B: Multi-hop - 公平版 (接收固定的干扰项列表)\n",
    "def task_multihop(mem, distractors_hop1, distractors_hop2):\n",
    "    mem.reset()\n",
    "    city, country = \"Kyoto\", \"Japan\"\n",
    "    \n",
    "    # Hop 1\n",
    "    q1, a1 = \"Where is X?\", f\"X is in {city}.\"\n",
    "    thought1 = f\"X is located in {city}.\"\n",
    "    mem.add_special(q1, thought1, a1)\n",
    "    \n",
    "    for q, a in distractors_hop1:\n",
    "        mem.add(q, a)\n",
    "        \n",
    "    # Hop 2\n",
    "    q2, a2 = f\"Where is {city}?\", f\"{city} is in {country}.\"\n",
    "    thought2 = f\"{city} is located in {country}.\"\n",
    "    mem.add_special(q2, thought2, a2)\n",
    "    \n",
    "    for q, a in distractors_hop2:\n",
    "        mem.add(q, a)\n",
    "        \n",
    "    resp = generate(f\"Context:\\n{mem.get_context('Country?')}\\n\\nUser: Country?\\nAnswer:\")\n",
    "    return 1.0 if country in resp else (0.5 if city in resp else 0.0)\n",
    "\n",
    "print(colored(\">>> 任务逻辑优化完毕 (公平接口 + 固定测试集)。\", \"green\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "678ecbf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [Cell 4] 执行全维度对比实验 (The Main Engine)\n",
    "# ==============================================================================\n",
    "# 目的: 运行实验，记录 Score (效能) 和 Latency (效率)。\n",
    "# 优化: 在每种强度下预生成固定数据集，确保所有方法“做同一套卷子”。\n",
    "# ==============================================================================\n",
    "\n",
    "def run_benchmark_optimized():\n",
    "    # 初始化 WandB\n",
    "    wandb.init(project=\"Memory-Comparison-Final\", name=\"Fair-Comparison-Fixed-Seed\")\n",
    "    \n",
    "    NUM_REPEATS = 3  # 每个任务重复3次\n",
    "    \n",
    "    methods = {\n",
    "        \"1. Baseline\": ConcatMemory(limit=5),\n",
    "        \"2. RAG\": RAGMemory(top_k=3),\n",
    "        \"3. Cheatsheet\": DynamicCheatsheetMemory(),\n",
    "        \"4. Titans\": TitansMemory(),\n",
    "        \"5. TAC (Ours)\": TACMemory(limit=3)\n",
    "    }\n",
    "    \n",
    "    # 强度梯度\n",
    "    intensity_levels = [5, 10, 20, 30]\n",
    "    \n",
    "    all_results_table = wandb.Table(columns=[\"Method\", \"Intensity\", \"Score\", \"Latency\"])\n",
    "    \n",
    "    print(colored(\"=== 开始双维度评估 (效能 vs 效率 | 公平对比模式) ===\", \"yellow\"))\n",
    "    \n",
    "    for intensity in intensity_levels:\n",
    "        print(colored(f\"\\n>>> Current Intensity: {intensity}\", \"white\", attrs=[\"bold\"]))\n",
    "        \n",
    "        # --- 关键优化：预生成该强度的标准考卷 (Standard Test Suite) ---\n",
    "        # 1. 为 NIAH 生成固定密码和固定干扰项\n",
    "        fixed_niah_code = f\"Alpha-{random.randint(100,999)}\"\n",
    "        fixed_niah_distractors = get_distractors(intensity)\n",
    "        \n",
    "        # 2. 为 Multi-hop 生成两组固定干扰项\n",
    "        fixed_multihop_d1 = get_distractors(intensity // 2)\n",
    "        fixed_multihop_d2 = get_distractors(intensity // 2)\n",
    "        \n",
    "        print(f\"    [Setup] Generated fixed test set for intensity {intensity}.\")\n",
    "\n",
    "        for name, mem in methods.items():\n",
    "            print(f\"   Testing {name}...\", end=\" \", flush=True)\n",
    "    \n",
    "            start_t = time.time()\n",
    "            scores = []\n",
    "            \n",
    "            for rep in range(NUM_REPEATS):\n",
    "                set_seed(42 + intensity + rep)  # 不同重复用不同种子\n",
    "                s1 = task_niah(mem, fixed_niah_code, fixed_niah_distractors)\n",
    "                s2 = task_multihop(mem, fixed_multihop_d1, fixed_multihop_d2)\n",
    "                scores.extend([s1, s2])\n",
    "            \n",
    "            avg_score = mean(scores)\n",
    "            duration = time.time() - start_t\n",
    "            \n",
    "            print(f\"-> Score: {avg_score:.2f} | Time: {duration:.1f}s\")\n",
    "            \n",
    "            wandb.log({\n",
    "                \"intensity\": intensity,          \n",
    "                f\"score_{name}\": avg_score,      \n",
    "                f\"latency_{name}\": duration,     \n",
    "                \"method_name\": name              \n",
    "            })\n",
    "            \n",
    "            all_results_table.add_data(name, intensity, avg_score, duration)\n",
    "            \n",
    "    wandb.log({\"All_Results\": all_results_table})\n",
    "    wandb.finish()\n",
    "    print(colored(\"\\n>>> 实验结束！请前往 WandB 查看两张核心图表。\", \"green\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "54298a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20251226_022039-7np560uu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/cloudingyu-fudan-university/Memory-Comparison-Final/runs/7np560uu' target=\"_blank\">Fair-Comparison-Fixed-Seed</a></strong> to <a href='https://wandb.ai/cloudingyu-fudan-university/Memory-Comparison-Final' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/cloudingyu-fudan-university/Memory-Comparison-Final' target=\"_blank\">https://wandb.ai/cloudingyu-fudan-university/Memory-Comparison-Final</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/cloudingyu-fudan-university/Memory-Comparison-Final/runs/7np560uu' target=\"_blank\">https://wandb.ai/cloudingyu-fudan-university/Memory-Comparison-Final/runs/7np560uu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 开始双维度评估 (效能 vs 效率 | 公平对比模式) ===\n",
      "\n",
      ">>> Current Intensity: 5\n",
      "    [Setup] Generated fixed test set for intensity 5.\n",
      "   Testing 1. Baseline... -> Score: 0.00 | Time: 25.5s\n",
      "   Testing 2. RAG... -> Score: 0.50 | Time: 7.7s\n",
      "   Testing 3. Cheatsheet... -> Score: 0.00 | Time: 68.4s\n",
      "   Testing 4. Titans... -> Score: 0.00 | Time: 37.8s\n",
      "   Testing 5. TAC (Ours)... -> Score: 1.00 | Time: 2.8s\n",
      "\n",
      ">>> Current Intensity: 10\n",
      "    [Setup] Generated fixed test set for intensity 10.\n",
      "   Testing 1. Baseline... -> Score: 0.00 | Time: 13.7s\n",
      "   Testing 2. RAG... -> Score: 0.33 | Time: 14.6s\n",
      "   Testing 3. Cheatsheet... -> Score: 0.00 | Time: 112.0s\n",
      "   Testing 4. Titans... -> Score: 0.00 | Time: 50.0s\n",
      "   Testing 5. TAC (Ours)... -> Score: 1.00 | Time: 2.4s\n",
      "\n",
      ">>> Current Intensity: 20\n",
      "    [Setup] Generated fixed test set for intensity 20.\n",
      "   Testing 1. Baseline... -> Score: 0.50 | Time: 24.7s\n",
      "   Testing 2. RAG... -> Score: 0.50 | Time: 21.3s\n",
      "   Testing 3. Cheatsheet... -> Score: 0.00 | Time: 193.8s\n",
      "   Testing 4. Titans... -> Score: 0.00 | Time: 90.0s\n",
      "   Testing 5. TAC (Ours)... -> Score: 1.00 | Time: 2.6s\n",
      "\n",
      ">>> Current Intensity: 30\n",
      "    [Setup] Generated fixed test set for intensity 30.\n",
      "   Testing 1. Baseline... -> Score: 0.00 | Time: 9.3s\n",
      "   Testing 2. RAG... -> Score: 0.50 | Time: 16.6s\n",
      "   Testing 3. Cheatsheet... -> Score: 0.00 | Time: 245.0s\n",
      "   Testing 4. Titans... -> Score: 0.00 | Time: 129.9s\n",
      "   Testing 5. TAC (Ours)... -> Score: 1.00 | Time: 2.6s\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>intensity</td><td>▁▁▁▁▁▂▂▂▂▂▅▅▅▅▅█████</td></tr><tr><td>latency_1. Baseline</td><td>█▃█▁</td></tr><tr><td>latency_2. RAG</td><td>▁▅█▆</td></tr><tr><td>latency_3. Cheatsheet</td><td>▁▃▆█</td></tr><tr><td>latency_4. Titans</td><td>▁▂▅█</td></tr><tr><td>latency_5. TAC (Ours)</td><td>█▁▄▃</td></tr><tr><td>score_1. Baseline</td><td>▁▁█▁</td></tr><tr><td>score_2. RAG</td><td>█▁██</td></tr><tr><td>score_3. Cheatsheet</td><td>▁▁▁▁</td></tr><tr><td>score_4. Titans</td><td>▁▁▁▁</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>intensity</td><td>30</td></tr><tr><td>latency_1. Baseline</td><td>9.33646</td></tr><tr><td>latency_2. RAG</td><td>16.64786</td></tr><tr><td>latency_3. Cheatsheet</td><td>244.97898</td></tr><tr><td>latency_4. Titans</td><td>129.85149</td></tr><tr><td>latency_5. TAC (Ours)</td><td>2.5562</td></tr><tr><td>method_name</td><td>5. TAC (Ours)</td></tr><tr><td>score_1. Baseline</td><td>0</td></tr><tr><td>score_2. RAG</td><td>0.5</td></tr><tr><td>score_3. Cheatsheet</td><td>0</td></tr><tr><td>+2</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Fair-Comparison-Fixed-Seed</strong> at: <a href='https://wandb.ai/cloudingyu-fudan-university/Memory-Comparison-Final/runs/7np560uu' target=\"_blank\">https://wandb.ai/cloudingyu-fudan-university/Memory-Comparison-Final/runs/7np560uu</a><br> View project at: <a href='https://wandb.ai/cloudingyu-fudan-university/Memory-Comparison-Final' target=\"_blank\">https://wandb.ai/cloudingyu-fudan-university/Memory-Comparison-Final</a><br>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20251226_022039-7np560uu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> 实验结束！请前往 WandB 查看两张核心图表。\n"
     ]
    }
   ],
   "source": [
    "# %% [Cell 5] 启动\n",
    "if __name__ == \"__main__\":\n",
    "    run_benchmark_optimized()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
